Deep Learning Project



Abstract:


Conversing with people having a hearing disability is a major challenge. Deaf and Mute people
use hand gesture sign language to communicate, hence normal people face problems in
recognizing their language by signs made. Hence there is a need for systems that recognize the
different signs and conveys the information to normal people.


Question/need:



Data Description:



I will be using 2 datasets and then compare the results.

Dataset 1: MNIST Dataset : 28×28 pixels images

Dataset 2: Image Dataset: 200×200 pixels images


Tools:


I will use python because it contains libraries for Machine Learning also for exploratory analysis and data cleaning will use (pandas, Matplotlib, NumPy ,etc.).
 Make a model which can recognize Fingerspelling-based hand gestures in order to form a
 complete word by combining each gesture.
  









#Deep-Learning
